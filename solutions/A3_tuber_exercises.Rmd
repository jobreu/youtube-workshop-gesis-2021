---
title: 'Exercises Collecting data with the tuber package for R - Solutions'
# title: 'Exercises Collecting data with the tuber package for R' 
author: 'Julian Kohne, Johannes Breuer, M. Rohangis Mohseni'
date: 'Automatic sampling and analysis of YouTube data, February 24-25, 2021'
output:
  unilur::tutorial_html_solution: default
  # unilur::tutorial_html: default
---

```{r knitr_init, echo=FALSE, cache=FALSE, include=FALSE}
# custom boxes
knitr::opts_template$set(clues = list(box.title = "Clues",
                                      box.body = list(fill = "#fff9dc", colour = "black"),
                                      box.header = list(fill = "#ffec8b", colour = "black"),
                                      box.icon = "fa-search",
                                      box.collapse = TRUE))

```

```{r klippy, echo=FALSE, include=TRUE}
klippy::klippy()
```

In the following exercises we will collect and explore some data from *YouTube*.

Before we start with this exercise, three short notes on working with the exercise files in this workshop:

1. You can find the solutions for this exercise as well as all other exercises in the `solutions` folder in the repo/directory that contains the course materials. You can copy code from these exercise files by clicking on the small blue clipboard icon in the upper right corner of the code boxes.

2. We would like to ask you to solve all coding tasks by writing them into your own `R` script files. This ensures that all of your solutions are reproducible, and that you can (re-)use solutions from earlier exercises in later ones.

3. All exercises and their solutions 'assume' they are in the `solutions` folder within the folder that contains the materials for this course. This way they can make use of files in other folders using relative paths. In order for your scripts to run properly, we suggest that you create (and save) them in the `my_code` folder (which already includes an almost empty script that you can continue to work with). For the relative file paths to work, you will also need to set your working directory to the folder that contains the script. Otherwise, you may have to change the (relative) file paths in your scripts accordingly.

Now let's get to it...

```{block, box.title = "1", box.body = list(fill = "white"), box.icon = "fa-star"}
Before we can start collecting data through the *YouTube* API, you first need to set up your API authorization. In case you have not already done that, please do so now.
```

```{block, opts.label = "clues"}
To set up your *YouTube* API authorization you need to use the function `yt_oauth` from the `tuber` package which requires the ID of your app as well as your app secret as arguments.
```

```{r API authorization, solution = TRUE, eval = F}
library(tuber)

yt_oauth(app_id = "my_app_id", # paste your app ID here
         app_secret = "my_app_secret", # paste your app secret here
         token="")

# alternatively, you can also use the keyring package (see slides)
```

While going through the following exercises you might want to monitor your API quota usage via the [*Google Cloud Platform*](https://console.cloud.google.com) dashboard for your app:  Select APIs & Services -> Dashboard.

```{block, box.title = "2", box.body = list(fill = "white"), box.icon = "fa-star"}
How many views, subscribers, and videos does the [*GESIS* channel](https://www.youtube.com/user/GESIStv) currently have?
```

```{block, opts.label = "clues"}
To get channel statistics you can use the `get_channel_stats` function which requires the ID the channel (as a string) as its main argument.
```

```{r channel stats, solution = TRUE, eval = F}
get_channel_stats("UCiQ98odXlAkX63EaFWNjH0g")
```

```{block, box.title = "3", box.body = list(fill = "white"), box.icon = "fa-star"}
How many views, likes, and comments does the music video "Data Science" by Baba Brinkman have?
```

```{block, opts.label = "clues"}
To answer this question you can use `get_stats` and need the ID of the video.
```

```{r video stats, solution = TRUE, eval = F}
get_stats("uHGlCi9jOWY")
```

```{block, box.title = "4", box.body = list(fill = "white"), box.icon = "fa-star"}
Collect all comments (including replies) for the video on "The Census" by Last Week Tonight with John Oliver. As we want to use the comments for later exercises, please assign the results to an object called `comments_lwt_census`.
```

```{block, opts.label = "clues"}
To get all comments including replies you need to use the function `get_all_comments`.
```

```{r get comments, solution = TRUE, eval = F}
comments_lwt_census <- get_all_comments("1aheRpmurAo")
```

NB: If you check the comment count on the website of the video you will see that there are more comments than in the dataframe you just created. This is because `get_all_comments` from `tuber` only collects up to 5 replies per comment.

```{block, box.title = "5", box.body = list(fill = "white"), box.icon = "fa-star"}
As a final step we want to save the comments we just collected so we can use them again in the exercises for the following sessions. Please save the the comments as an .rds file.
```

```{block, opts.label = "clues"}
To save an .rds file you can use the `base R` function `saveRDS`. For those, you should create a `data` subfolder in the folder that contains the workshops materials. The code in the solution assumes that your working directory is the `my_code` folder (or some other subfolder within the one that contains the course materials) and stores the file in the `data` folder that you should have (created).
```

```{r save, solution = TRUE, eval = F}
saveRDS(comments_lwt_census, "../data/RawComments.rds")
```
