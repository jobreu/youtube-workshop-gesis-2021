--- 
title: "Automatic Sampling and Analysis of YouTube Data"
subtitle: "Excursus: Retrieving Video Subtitles"
author: "Julian Kohne<br />Johannes Breuer<br />M. Rohangis Mohseni"
date: "2021-02-25"
location: "GESIS, online" 
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "default-fonts", "../workshop.css"]
    nature:
      highlightStyle: "github"
      highlightLines: true
      countIncrementalSlides: false

---

layout: true

```{r setup, include = F}
if (!require(easypackages)) install.packages("easypackages")
library(easypackages)
library(tuber)

packages("knitr",
         "rmarkdown",
         "tidyverse",
         "kableExtra",
         "hadley/emo",
         "fkeck/subtools",
         "tuber",
         prompt = F)

options(htmltools.dir.version = FALSE,
        htmltools.preserve.raw = FALSE)

opts_chunk$set(echo = FALSE,
               fig.align = "center")

xaringanExtra::use_xaringan_extra(c("tile_view", "clipboard"))
xaringanExtra::use_extra_styles(hover_code_line = TRUE,
                                mute_unhighlighted_code = FALSE)
```

<div class="my-footer">
  <div style="float: left;"><span>`r gsub("<br />", ", ", gsub("<br /><br />|<a.+$", "", metadata$author))`</span></div>
  <div style="float: right;"><span>`r metadata$location`, `r metadata$date`</span></div>
  <div style="text-align: center;"><span>`r gsub(".+<br />", " ", metadata$subtitle)`</span></div>
</div>

<style type="text/css">

pre {
  font-size: 10px
}
</style>

---


# Retrieving *YouTube* Video Subtitles

- Instead of transcribing a video, you can retrieve its subtitles via the *YouTube* API

- What research would you conduct with video subtitles?

---

# Types of *YouTube* Subtitles

- Videos with automatically created subtitles (<i>ASR</i>)

  - Always in English, even if video language is not English

  - Can be downloaded, but text quality can be bad (especially if translated)

- Videos without any subtitles

  - Not sure if even possible because there always seems to be an <i>ASR</i>
  
- Videos with more than one set of subtitles

  - Examples: <i>ASR</i> and regular subtitle, more than one language, more than one subtitle for the same language

  - Can be downloaded, but subtitle for analysis must be selected

---

# Disclaimer

Due to a recent change to the *YouTube* API, the `tuber` function for retrieving video subtitles seems to only work for videos that were created with the same account as the app used for the API access (see this [closed `tuber` issue on GitHub](https://github.com/soodoku/tuber/issues/78). We will still discuss this function, but recommend that you use the [`youtubecaption` package](https://github.com/jooyoungseo/youtubecaption) for collecting subtitles for videos that you have not created yourself. 

---

# Retrieving Video Subtitles with `tuber`

- Retrieve a list of subtitles with

  - `tuber::list_caption_tracks()`
  
- Quota costs ~ 50
  
---

# Retrieving Video Subtitles with `tuber`

- First, we need to get the list of subtitles for a video

  `caption_list <- list_caption_tracks(video_id = "nI_OfkQOG6Q")`

- Next, we need to get the ID of the subtitles we want to collect

  `ID <- caption_list[1,"id"]`
  
- Adapt the number to select the subtitle that you want (ASR = automatic sub)

- After that, we need to retrieve the subtitles and convert them from raw to char

  `text <- rawToChar(get_captions(id = ID, format = "sbv"))`

- Now we can save the subtitles to a subtitle file

  `write(text, file = "Captions.sbv", sep="\n")`

---

# Converting Subtitles

- Subtitles come in a special format called SBV

- The format contains time stamps etc. that we do not need for text analysis

- We can read the format with the package [`subtools`](https://github.com/fkeck/subtools)

 `subs <- read_subtitles("Captions.sbv", format = "subviewer")`
 
- With subtools, we can also retrieve the text from the subtitles

  `subtext <- get_raw_text(Subs)`

- Now the text is ready for text analysis

---

# Retrieving Video Subtitles with `youtubecaption`

- Alternatively, you can retrieve captions with the package [`youtubecaption`](https://github.com/jooyoungseo/youtubecaption)

- **Pros**:

  - No credentials necessary, therefore no quota reduction
  
  - Subtitles are automatically converted into a dataframe including texts and timestamps, so no manual conversion is needed
  
- **Cons**:

  - If there is more than one subtitle version per language, there is no way to select a specific one
  
  - You need to install [*Anaconda*](https://www.anaconda.com/products/individual)

---

# Time for a Short Live Demo

```{r cases, out.width = "75%"}
include_graphics("./Images/youtubesubtitles.jpg")
```

**Note**: You can find the code for collecting subtitles for *YouTube* videos in the `YouTubeSubtitles.R` file in the `scripts` folder.

---

class: center, middle

# Any (further) questions?