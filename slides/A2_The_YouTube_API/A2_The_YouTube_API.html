<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Automatic Sampling and Analysis of YouTube Data</title>
    <meta charset="utf-8" />
    <meta name="author" content="Julian Kohne Johannes Breuer M. Rohangis Mohseni" />
    <meta name="date" content="2021-02-24" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="../workshop.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Automatic Sampling and Analysis of YouTube Data
## The YouTube API
### Julian Kohne<br />Johannes Breuer<br />M. Rohangis Mohseni
### 2021-02-24

---




&lt;div class="my-footer"&gt;
  &lt;div style="float: left;"&gt;&lt;span&gt;Julian Kohne, Johannes Breuer, M. Rohangis Mohseni&lt;/span&gt;&lt;/div&gt;
  &lt;div style="float: right;"&gt;&lt;span&gt;GESIS, online, 2021-02-24&lt;/span&gt;&lt;/div&gt;
  &lt;div style="text-align: center;"&gt;&lt;span&gt;The YouTube API&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;

---

class: center, middle

# The YouTube API

---
# Overview

- All data on YouTube is stored in a [MySQL](https://en.wikipedia.org/wiki/MySQL) database
 
- The website itself is an HTML page, which loads content from this database

- The HTML is rendered by a webbrowser so the user can interact with it

- Through interacting with the rendered website, we can either retrieve content from the database
or send information to the database

- The YouTube Website is
    - built in [HTML](https://de.wikipedia.org/wiki/Hypertext_Markup_Language), 
    - uses [CSS](https://de.wikipedia.org/wiki/Cascading_Style_Sheets) for the "styling"
    - dynamically loads content using [Ajax](https://en.wikipedia.org/wiki/Ajax) from the Database

![plot](Images/YouTube_better.png)
---
# How do we get Data From Websites?

- Theoretically, we could gather all the information manually by clicking on the things that are
 interesting to us and copy/pasting them. However, this is tedious and time-consuming. **We want a way
 of automatizing this task**

- [Webscraping](https://en.wikipedia.org/wiki/Web_scraping)

  1) **Screenscraping:** Getting the HTML-code out of your browser, parsing &amp; formatting it, then analyzing the data
  
  2) **API-harvesting:** Sending requests directly to the database and only getting back the information that you want and need.

---
class: center, middle
# Screenscraping

---
# Screenscraping

- Screenscraping means that we are downloading the HTML text file, which contains the content we are interested in but also a lot of unnecessary clutter that describes how the website should be rendered by the browser

![plot](Images/Screenscraping_2.png)

---
# Screenscraping

![plot](Images/BBC2.png)

---
# Screenscraping

- To automatically obtain data, we can use a so called [GET request](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol)

- A GET request is an HTTP method for asking a server to send a specific resource (usually an HTML page) back
to your local machine

- You can try it out in your console

- This is the basic principle that all the Scraping packages build-on

- We will not use this directly and will let the higher-level applications handle this under the hood

---
# Screenscraping

- Advantages of Screenscraping:
  + You can access everything that you are able to access from your browser
  + You are (theoretically) not restricted in how much data you can get
  + (Theoretically) Independent from API-restrictions

- Disadvantages of Screenscraping:
  - Extremely tedious to get information out of HTML-pages
  - You have to manually look up the Xpaths/CSS/HTML containers to get specific information
  - Reproducibility: The website might be tailored to stuff in your Cache, Cookies, Accounts etc.
  - There is no guarantee that even pages that look the same have the same underlying HTML structure
  - You have to manually check the website and your data to make sure that you're getting what you want
  - If the website changes anything in their styling, your scripts won't work anymore
  - [Legalality](https://en.wikipedia.org/wiki/Web_scraping#Legal_issues) depends on country

---
class: center, middle
# API-Harvesting

---
# API-Harvesting

- An [**A**pplication **P**rogramming **I**nterface]([API](https://en.wikipedia.org/wiki/Application_programming_interface)) is:
  - a system build for developers
  - directly communicating with the database
  - Voluntary service of the website
  - dictating what information is accessible, to whom, how, and in which quantities.

![plot](Images/API_harvesting.png)

---
# API-Harvesting

- APIs can be used to:

  - embed content in other applications
  - create Bots that do something automatically
  - scheduling/moderation for content creators
  - collect data for (market) research purposes

- Not every website has their own API. However, most large Social Media Websites do
  - [Facebook](https://developers.facebook.com/docs/graph-api?locale=de_DE)
  - [Twitter](https://developer.twitter.com/en/docs/basics/getting-started)
  - [Instagram](https://www.instagram.com/developer/)
  - [Wikipedia](https://en.wikipedia.org/w/api.php)
  - [Google Maps](https://www.programmableweb.com/api/google-maps-places)

---
# API-Harvesting

- Advantages of API-Harvesting:
  + No need to interact with HTML files, you only get the information you asked for
  + The data you get is already nicely formatted (usually JSON files)
  + You can be sure that what you do is legal and (probably) in line with Terms of Service

- Disadvantages of API-Harvesting:
  - Not every website has an API
  - You can only get what the API allows you to get
  - There are often restricting quotas (e.g. daily limits)
  - there is no standard language to make queries, you have to check the documentation
  - Not every API has a (good) documentation
  
---
class: inverse, middle, center
# Screenscraping vs. API-Harvesting

If you can, use an API, if you must, use Screenscraping instead

---
class: center, middle
# The YouTube API

---
# Summary

- Fortunately, YouTube has their own, well-documented API
  that developers can use to interact with their database (Most Google Services do)

- To find an API for a given website, [Programmable Web](https://www.programmableweb.com/category/all/apis) is
  a good starting point

- We will use the [YouTube API](https://developers.google.com/youtube/v3/docs) today

---
# Let's Check the API

- Google provides a sandbox for their API that we can use to get a grasp of how it operates

- We can for example use our credentials to get search for videos with the keyword "Brexit"

- [Example](https://developers.google.com/youtube/v3/docs/search/list?apix_params=%7B%22part%22%3A%22snippet%22%2C%22q%22%3A%22Brexit%22%7D)

- Keep in mind: We have to log in with our created Google account to use the API

- What we get back is a JSON formatted response with the formats and information we requested in the Sandbox

---
# What is JSON?

- [Java Script Object Notation](https://en.wikipedia.org/wiki/JSON)

- Language independent data format (like .csv)

- Like a nested List of Key:Value pairs

- Standard data format for many APIs and web applications

- Better than tabular formats (.csv / .tsv) at storing large quantities of data by not declaring missing data

- Represented in R as a list of lists, needs to be transformed into a regular dataframe (this can be tedious)

---
# What is JSON?


```r
'{
  "first name": "John",
  "last name": "Smith",
  "age": 25,
  "address": {
    "street address": "21 2nd Street",
    "city": "New York",
    "postal code": "10021"
  },
  "phone numbers": [
    {
      "type": "home",
      "number": "212 555-1234"
    },
    {
      "type": "mobile",
      "number": "646 555-4567"
    }
  ],
  "sex": "male"
}'
```

---
# Most Important Parameters

- All possible parameters are listed [here](https://developers.google.com/youtube/v3/docs/search/)

- Keep in mind that some information is only visible to owners of a channel or author of a video

- Keep in mind that not all information is necessarily available for all videos (e.g. live videos)

---
# Using it from R

- We can simplyfiy the process of interacting with the YouTube API by using a dedicated R package

- The package handles the authentification with our credentials and translates R commands into API calls

- It also simplifies the JSON response to a standard dataframe automatically

- In essence, we can run R commands and get nicely formatted API results back

- For this workshop, we will thus use the [tubeR package](https://cran.r-project.org/web/packages/tuber/tuber.pdf)

---
# Rate Limits

- With the API, you have a limit of how much data you can get

- This limit has constantly decreased over the last decade

.center[![plot](Images/RateLimitReduction3.png)]

---
# Rate Limits

- Currently (02.2021), you have a quota of **10.000** units per day

- Each request (even invalid ones) costs a certain amount of units

- There are two factors influencing the quota cost of each request:

  - different types (e.g write operation: 50 units; video upload: 1600 units)
  
  - how many parts the requested resource has (playlist:2 ; channel:6 ; video:10)
  
- **You should only request parts that you absolutely need to make the most of your units. More on that in the data collection session. ** 

**BEWARE: Sending wrong requests can fill up your daily quota**

---
# Rate Limits

- You can check the rate limits in the [_YouTube_ API Documentation](https://developers.google.com/youtube/v3/getting-started#quota)

- You can see how much of your quota you have already used up in the developer console

![plot](Images/Quotas.png)

![plot](Images/Metrics.png)

---

# Raising the Quota Limit for YouTube 🤠

- Study planned that needs large datasets in short amounts of time

- RQ: Is there a u-shaped relationship between success and number of uploads?

- Sample: 600 popular channels (identified via SocialBlade) 

- Request for higher quota (October 11, 2019)

- Problem: Same application form for (web) apps and research

- Hard to figure what applies to research and what to write into the form

---
# Can I Increase my Rate Limit?

.center[![plot](Images/Odyssey4.jpg)]
  
---

class: center, middle

# Any questions?

---

class: center, middle

# [Exercise](https://jobreu.github.io/youtube-workshop-gesis-2021/exercises/A2_The_Youtube_API_question.html) time 🏋️‍♀️💪🏃🚴

## [Solutions](https://jobreu.github.io/youtube-workshop-gesis-2021/solutions/A2_The_Youtube_API_solution.html)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
